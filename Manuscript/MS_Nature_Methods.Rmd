---
title: 'MS Nature Methods'
csl: nature-methods.csl
indent: yes
output: bookdown::pdf_document2
toc: false
linestretch: 1.5
fontsize: 11pt
header-includes:
       - \usepackage{subfig}
abstract: \singlespacing Brief Communications begin with a brief unreferenced abstract (3 sentences, no more than 70 words),
bibliography: refs_repro.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# options(tinytex.verbose = TRUE)
```

```{r libraries, echo = FALSE, message = FALSE, warning = FALSE}
library(bookdown)
library(knitr)
library(tidyverse)
```


```{r data, include = FALSE, cache = FALSE}
load("all_outcomes_init_samp_size_10.RData")
load("exploratory_data_SESOI_Carneiro_10.RData")
load("exploratory_data_SESOI_Szucs_10.RData")
load("exploratory_data_significance_Carneiro_10.RData")
load("exploratory_data_significance_Szucs_10.RData")
```

**Main**

\ \ \ \ Preclinical research is essential for identifying promising interventions and to generate robust evidence to support translation to humans. Experiments in a preclinical setting are conducted in two different operating modes [@kimmelman2014distinguishing]. Early-stage preclinical experiments are *exploratory* with the aim to discover potentially effective interventions and generate hypotheses. These are tested at a later stage under more strict conditions in *confirmatory* mode [@landis2012call].

Various publications have called for a distinction between exploration and confirmation in preclinical animal research [@dirnagl2016thomas; @kimmelman2014distinguishing; @landis2012call]. Mogil & Macleod [@mogil2017no] took up this sentiment and proposed that an initial claim must be independently confirmed in order to be published. This suggestion emphasizes confirmation of initial findings. However, the question remains which exploratory results should be contested during confirmation. There is currently no guidance regarding criteria that should be applied to make this decision. 

Commonly, the *p*-value is used to make a decision whether or not to further investigate a claim. Given that prior probabilities at this stage of discovery are low and sample sizes are small [@macleod2008evidence; @howells2014bringing], the *p*-value might prematurely discard potentially promising interventions [@dirnagl2020resolving].

Exploration requires sensitive tests to detect rare and possibly small effects [@bonapersona2019repair; @dirnagl2020resolving]. As more sensitive criteria invite more false positive results, confirmation must aim at reducing false positives to ensure that only true effects are carried forward to clinical testing. To increase power and safeguard reliability of results, sample sizes must be increased when switching from exploratory to confirmatory mode. However, ethical, time, and budget constraints prevent preclinical researchers from increasing their sample size and thus complicate the detection and precise estimation of effects. In an effort to prevent false negative results in exploration and reduce false positives during confirmation, it is necessary to devise strategies to move from exploration to confirmation that meet these complementary goals.

Here, we consider how to move from exploratory to confirmatory mode while balancing the number of animals against the likelihood of false negative and false positive outcomes. 

To this end, we simulated two preclinical research trajectories comprising an exploratory study and a first confirmatory study (Figure 1?). 

We based our simulations on two empirical effect size distributions reflecting an *optimistic* (high pre-study odds) and a *pessimistic* (low pre-study odds) scenario. After an initial exploratory study, a first decision identified experiments that should move from exploratory to confirmatory mode. One trajectory (standard) employed the conventional significance threshold ($\alpha$ = .05) for this decision. The second trajectory (SESOI) used a more lenient threshold based on an *a priori* determined smallest effect size of interest (SESOI). 

In the standard trajectory, in the optimistic scenario, `r outcomes_all_distributions_init_samp_size_10$rep_attempts[8] / 100` percent of experiments met the criterion *p* $\leq$ .05. In the pessimistic scenario, `r outcomes_all_distributions_init_samp_size_10$rep_attempts[4] / 100` percent of experiments had a *p*-value $\leq$ .05. A closer look at the effect sizes of the experiments that proceeded to replication reveals that the conventional significance threshold is a conservative filter. Many effect sizes smaller than 1 but larger than 0 are eliminated and are not further investigated (Figure \@ref(fig:histograms)a--b). This demonstrates that the conventional significance threshold is not useful to screen for potentially meaningful effects at the early stages of drug discovery even if pre-study odds are high.

In the SESOI trajectory, we estimated the exploratory effect size and 95 percent confidence interval (CI) around that estimate. We examined whether the CI covered our SESOI (0.5 and 1.0, respectively). If this was the case for an experiment, it advanced to confirmatory mode. Importantly, we did not consider the *p*-value additionally. Applying this decision criterion resulted in `r outcomes_all_distributions_init_samp_size_10$rep_attempts[6] / 100` and `r outcomes_all_distributions_init_samp_size_10$rep_attempts[5] / 100` percent of experiments moving to confirmation in case of the optimistic distribution and `r outcomes_all_distributions_init_samp_size_10$rep_attempts[2] / 100` and `r outcomes_all_distributions_init_samp_size_10$rep_attempts[1] / 100` percent for the pessimistic distribution based on an SESOI of 0.5 and 1.0, respectively. Compared to the conventional significance threshold, the range of effect size estimates that proceeded to confirmation shifted and included less extreme values, as well as more values closer to zero (Figure \@ref(fig:histograms)c--f). This decision criterion meets the goal of keeping the false negative rate low better than the conventional significance threshold.

```{r histograms, echo = FALSE, fig.cap = 'Samples (n = 10000) drawn from the two empirical effect size distributions (left: optimistic, right: pessimistic). The panels show the underlying effect sizes that were detected using one of the two decision criteria. Orange shaded bars (panels (a) and (b)) indicate those effect sizes that were identified for replication using the conventional significance threshold (p = .05). Blue shaded bars indicate effect sizes that were selected using a SESOI of 0.5 (panels (c) and (d)) or 1.0 (panels (e) and (f)), respectively. Note that in (a), (c), and (e) 16 values $>$ 10 were removed in order to display the distribution.', fig.subcap = c('', ''), out.width = '.50\\linewidth', fig.ncol = 2, fig.align = 'center'}

exploratory_data_sig_Szucs_10 <-
  exploratory_data_sig_Szucs_10 %>% 
  filter(pval_threshold == 0.05) %>% 
  filter(ES_true <= 10)
  
ES_histrogram_Szucs_selected_sig <-
  ggplot(data = exploratory_data_sig_Szucs_10, 
       aes(x = ES_true, fill = factor(selection_sig))) +
  geom_histogram(bins = 90, color = "black",
                 size = 0.3, alpha = 0.8) +
  labs(#x = "",
       x = expression(paste("Cohen's ", italic("d"))),
       y = "Frequency",
       fill = "Selected for \nreplication") +
  scale_fill_manual(breaks = c("0", "1"),
                    labels = c("no",
                               "yes"),
                    values = c("white", "#E69F00")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(legend.position = "none")

ES_histrogram_Szucs_selected_sig

exploratory_data_sig_Carneiro_10 <-
  exploratory_data_sig_Carneiro_10 %>% 
  filter(pval_threshold == 0.05)

ES_histrogram_Carneiro_selected_sig <-
  ggplot(data = exploratory_data_sig_Carneiro_10, 
       aes(x = ES_true, fill = factor(selection_sig))) +
  geom_histogram(bins = 90, color = "black",
                 size = 0.3, alpha = 0.8) +
  labs(#x = "",
       x = expression(paste("Cohen's ", italic("d"))),
       y = "Frequency",
       fill = "Selected for \nreplication") +
  scale_fill_manual(breaks = c("0", "1"),
                    labels = c("no",
                               "yes"),
                    values = c("white", "#E69F00")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(legend.position = "none")

ES_histrogram_Carneiro_selected_sig

exploratory_data_Szucs_10_0.5 <-
  exploratory_data_Szucs_10 %>% 
  filter(SESOI == 0.5) %>% 
  filter(ES_true <= 10)

ES_histrogram_Szucs_selected_SESOI_0.5 <-
  ggplot(data = exploratory_data_Szucs_10_0.5, 
       aes(x = ES_true, fill = factor(selection_equiv))) +
  geom_histogram(bins = 90, color = "black",
                 size = 0.3, alpha = 0.8) +
  labs(#x = "",
       x = expression(paste("Cohen's ", italic("d"))),
       y = "Frequency",
       fill = "Selected for \nreplication") +
  scale_fill_manual(breaks = c("0", "1"),
                    labels = c("no",
                               "yes"),
                    values = c("white", "#0072B2")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(legend.position = "none")

ES_histrogram_Szucs_selected_SESOI_0.5


exploratory_data_Carneiro_10_0.5 <-
  exploratory_data_Carneiro_10 %>% 
  filter(SESOI == 0.5)

ES_histrogram_Carneiro_selected_SESOI_0.5 <-
  ggplot(data = exploratory_data_Carneiro_10_0.5, 
       aes(x = ES_true, fill = factor(selection_equiv))) +
  geom_histogram(bins = 90, color = "black",
                 size = 0.3, alpha = 0.8) +
  labs(#x = "",
       x = expression(paste("Cohen's ", italic("d"))),
       y = "Frequency",
       fill = "Selected for \nreplication") +
  scale_fill_manual(breaks = c("0", "1"),
                    labels = c("no",
                               "yes"),
                    values = c("white", "#0072B2")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(legend.position = "none")

ES_histrogram_Carneiro_selected_SESOI_0.5

exploratory_data_Szucs_10_1.0 <-
  exploratory_data_Szucs_10 %>% 
  filter(SESOI == "1.0") %>% 
  filter(ES_true <= 10)

ES_histrogram_Szucs_selected_SESOI_1.0 <-
  ggplot(data = exploratory_data_Szucs_10_1.0, 
       aes(x = ES_true, fill = factor(selection_equiv))) +
  geom_histogram(bins = 90, color = "black",
                 size = 0.3, alpha = 0.8) +
  labs(#x = "",
       x = expression(paste("Cohen's ", italic("d"))),
       y = "Frequency",
       fill = "Selected for \nreplication") +
  scale_fill_manual(breaks = c("0", "1"),
                    labels = c("no",
                               "yes"),
                    values = c("white", "#0072B2")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(legend.position = "none")

ES_histrogram_Szucs_selected_SESOI_1.0


exploratory_data_Carneiro_10_1.0 <-
  exploratory_data_Carneiro_10 %>% 
  filter(SESOI == "1.0")

ES_histrogram_Carneiro_selected_SESOI_1.0 <-
  ggplot(data = exploratory_data_Carneiro_10_1.0, 
       aes(x = ES_true, fill = factor(selection_equiv))) +
  geom_histogram(bins = 90, color = "black",
                 size = 0.3, alpha = 0.8) +
  labs(#x = "",
       x = expression(paste("Cohen's ", italic("d"))),
       y = "Frequency",
       fill = "Selected for \nreplication") +
  scale_fill_manual(breaks = c("0", "1"),
                    labels = c("no",
                               "yes"),
                    values = c("white", "#0072B2")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(legend.position = "none")

ES_histrogram_Carneiro_selected_SESOI_1.0
```

```{r ES data, include = FALSE, cache = FALSE}
load("ES_data_Szucs.RData")
load("ES_data_Carneiro.RData")
```

```{r ES distribution, echo = FALSE, results = "hide"}
min(ES_data_Szucs$D)
max(ES_data_Szucs$D)

sum(ES_data_Szucs$D > 20)

median(ES_data_Szucs$D)
mean(ES_data_Szucs$D)

names(ES_data_Carneiro)[1] <- "D"

ES_data_Carneiro$D <- ifelse(ES_data_Carneiro$D < 0, -ES_data_Carneiro$D, -ES_data_Carneiro$D)

min(ES_data_Carneiro$D)
max(ES_data_Carneiro$D)
median(ES_data_Carneiro$D)
mean(ES_data_Carneiro$D)

ES_data_Carneiro <-
  ES_data_Carneiro %>% 
  mutate(distribution = "Pessimistic")

ES_Szucs <-
  ES_data_Szucs %>% 
  select(D) %>% 
  filter(D <= 20) %>% 
  mutate(distribution = "Optimistic")

ES_data <- bind_rows(ES_Szucs, ES_data_Carneiro)
```

In a second step, we calculated the sample size for a first confirmatory study. In the standard trajectory this was done via a standard power analysis using the initial exploratory effect size. The SESOI trajectory used again a pre-defined smallest effect size of interest (SESOI). Note that all sample sizes reported are the number of animals needed in *each* group (control and intervention).

In the standard trajectory, this resulted in a mean number of `r round(outcomes_all_distributions_init_samp_size_10$mean_N[7], 2)` (SD = `r round(outcomes_all_distributions_init_samp_size_10$mean_N[7] - outcomes_all_distributions_init_samp_size_10$mean_N_min[7], 2)`) animals in the optimistic, and `r round(outcomes_all_distributions_init_samp_size_10$mean_N[3], 2) ` (SD = `r round(outcomes_all_distributions_init_samp_size_10$mean_N[3] - outcomes_all_distributions_init_samp_size_10$mean_N_min[3], 2)`) in the pessimistic scenario. These small numbers reflect the large effect sizes that passed on to confirmation and were the basis for sample size calculation (Supplementary Figure 2a--b).


In the SESOI trajectory, the number of animals varied with the SESOI that was chosen. For an SESOI of 1.0, `r round(outcomes_all_distributions_init_samp_size_10$mean_N[1])` animals were needed in the replication in both the optimistic and pessimistic scenario. If the SESOI was 0.5, animal numbers increased to `r round(outcomes_all_distributions_init_samp_size_10$mean_N[2])` (Figure \@ref(fig:animalnumbers)). Note that the sample sizes reported are the number of animals needed in *each* group (control and intervention).


We further calculated the positive predictive value (PPV), false positive rate (FPR), and false negative rate (FNR) across both trajectories. The positive predictive value (PPV) of a study is the post-study probability that a positive finding which is based on statistical significance reflects a true effect [@ioannidis2005most]. The PPV is calculated from the pre-study odds, as well as the sensitivity and specificity of the test. In our study, pre-study odds of an effect of a given size (0.5 and 1.0, respectively) were determined by the empirical effect size distributions. If evidence for an initial claim is strengthened throughout the preclinical research trajectory, we would observe an increased PPV compared to pre-study odds.
In the optimistic scenario, the pre-study odds were `r round(outcomes_all_distributions_init_samp_size_10$prev_pop[6], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$prev_pop[5], 2)` for SESOI of 0.5 and 1.0, respectively. In the pessimistic scenario pre-study odds were `r round(outcomes_all_distributions_init_samp_size_10$prev_pop[2], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$prev_pop[1], 2)`, respectively. 
Across the standard trajectory, the PPV drops below pre-study odds in both scenarios (Figure \@ref(fig:PPV)). After the within-lab replication, the PPV is `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[8], 2)` and  `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[7], 2)` in the optimistic scenario for SESOI of 0.5 and 1.0, respectively. In the pessimistic scenario, the PPV is `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[4], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[3], 2)`.
In the SESOI trajectory, employing a SESOI at both stages along the decision-making process elevates the PPV above pre-study odds. Given a SESOI of 0.5 and 1.0, respectively, the PPV is `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[6], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[5], 2)` in the optimistic scenario, and `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[2], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$PPV_pop_prev[1], 2)` in the pessimistic scenario.
Across the standard trajectory, given the "optimistic" scenario, the FPR was `r round(outcomes_all_distributions_init_samp_size_10$FPR[8], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$FPR[7], 2)` for SESOI of 0.5 and 1.0, respectively. In the "pessimistic" scenario, the FPR was `r round(outcomes_all_distributions_init_samp_size_10$FPR[4], 3)` and `r round(outcomes_all_distributions_init_samp_size_10$FPR[3], 2)` for SESOI of 0.5 and 1.0, respectively.
Across the SESOI trajectory, the FPR increased to `r round(outcomes_all_distributions_init_samp_size_10$FPR[6], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$FPR[5], 2)` in the "optimistic" scenario for SESOI of 0.5 and 1.0. Given the "pessimistic" scenario, the FPR was `r round(outcomes_all_distributions_init_samp_size_10$FPR[2], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$FPR[1], 2)` for SESOI set to 0.5 and 1.0. 
Across the standard trajectory, given the "optimistic" scenario, the FNR was `r round(outcomes_all_distributions_init_samp_size_10$FNR[8], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$FNR[7], 2)` for SESOI set to 0.5 and 1.0, respectively.  In the "pessimistic" scenario, the FNR was `r round(outcomes_all_distributions_init_samp_size_10$FNR[4], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$FNR[3], 2)` for SESOI of 0.5 and 1.0, respectively.
Across the SESOI trajectory, the FNR decreased to `r round(outcomes_all_distributions_init_samp_size_10$FNR[6], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$FNR[5], 2)` in the "optimistic" scenario for SESOI set to 0.5 and 1.0. Given the "pessimistic" scenario, the FNR was `r round(outcomes_all_distributions_init_samp_size_10$FNR[2], 2)` and `r round(outcomes_all_distributions_init_samp_size_10$FNR[1], 2)` for SESOI of 0.5 and 1.0


```{r, echo = FALSE}

outcomes_all_distributions_init_samp_size_10$traject_SESOI <- 
  interaction(outcomes_all_distributions_init_samp_size_10$trajectory, outcomes_all_distributions_init_samp_size_10$SESOI)

plot_data_N <-
  outcomes_all_distributions_init_samp_size_10 %>% 
  filter(init_sample_size == 10) %>% 
  filter(traject_SESOI != "T1.1") %>% 
  group_by(distribution, SESOI)

plot_data <-
  outcomes_all_distributions_init_samp_size_10 %>% 
  filter(init_sample_size == 10) %>% 
  group_by(distribution, SESOI)
```

```{r results, echo = FALSE, message = FALSE, fig.cap = '(a) Number of animals needed in the first confirmatory study. In the standard trajectory, sample sizes are low, as they are based on large exploratory effect sizes. Error bars represent standard deviations. In case of trajectories using a SESOI, the number of animals is fixed. (b) Positive predictive value across trajectory. Dashed lines indicate pre-study odds based on empirical effect size distributions.', fig.subcap = c('', ''), out.width = '.50\\linewidth', fig.ncol = 2, fig.align = 'center'}

plot_mean_N <-
  ggplot(data = plot_data_N,
         aes(x = factor(traject_SESOI), y = mean_N, fill = factor(trajectory))) +
  geom_bar(stat = "identity", position = "dodge",
           size = .3,
           color = "black",
           alpha = 0.8) +
  geom_errorbar(aes(ymax = mean_N_max, ymin = mean_N_min), width = 0.1,
                position = position_dodge(width = 0.9)) +
  facet_grid(~ distribution) +
  # ggtitle("Mean number of animals for each trajectory") +
  labs(x = " ", y = "Mean # of animals in replication",
       fill = "Trajectory") +
  scale_x_discrete(labels = c("Standard", "SESOI = 0.5", "SESOI = 1.0")) +
  scale_fill_manual(labels = c("Standard", "SESOI"), values = c("#E69F00", "#0072B2")) + 
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 14, colour = "black",
                                   angle = 45, hjust = 1)) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  # theme(axis.title.x = element_text(size = 14)) +
  # theme(axis.title.y = element_text(size = 14)) +
  # theme(axis.text.x = element_text(size = 12, colour = "black")) +
  # theme(axis.text.y = element_text(size = 12, colour = "black")) +
  theme(strip.text.x = element_text(size = 14, colour = "black")) +
  theme(strip.background = element_rect(fill = "white", color = "black")) +
  theme(legend.title = element_text(size = 13, face = "bold")) +
  theme(legend.text = element_text(size = 12)) +
  theme(legend.position = "none")
  # theme(title = element_text(size = 15))

plot_mean_N

facet_names <- 
  c("0.5" = "SESOI = 0.5",
    "1" = "SESOI = 1.0")

plot_PPV <-
  ggplot(data = plot_data, 
         aes(x = factor(trajectory), 
             y = PPV_pop_prev,
             color = trajectory)) +
  geom_point(size = 3) +
  facet_grid(SESOI ~ distribution, labeller = labeller(.rows = facet_names)) +
  labs(x = "Trajectory", y = "Positive predictive value") +
  scale_x_discrete(labels = c("Standard", "SESOI")) +
  scale_color_manual(breaks = c("T1", "T2"),
                    values = c("#E69F00", "#0072B2")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(strip.text.x = element_text(size = 14, colour = "black")) +
  theme(strip.text.y = element_text(size = 14, colour = "black")) +
  theme(strip.background = element_rect(fill = "white", color = "black")) +
  theme(legend.position = "none")

hlines <- data.frame(pre_study_odds = c(plot_data$Prevalence[1], plot_data$Prevalence[2],
                                        plot_data$Prevalence[5], plot_data$Prevalence[6]), 
                     distribution   = c(rep(plot_data$distribution[1], 2), 
                                        rep(plot_data$distribution[5], 2)),
                     SESOI          = rep(c("1", "0.5"))) 

plot_PPV <- 
  plot_PPV + 
  geom_hline(data = hlines, 
             aes(yintercept = pre_study_odds),
             color = "black", lty = 2, size = .5)

plot_PPV

facet_names <- c(
  "0.5" = "SESOI = 0.5",
  "1" = "SESOI = 1.0")

plot_FPR <-
  ggplot(data = plot_data, 
         aes(x = factor(trajectory), 
             y = FPR,
             color = trajectory)) +
  geom_point(size = 3, alpha = .8) +
  facet_grid(SESOI ~ distribution, labeller = labeller(.rows = facet_names)) +
  labs(x = "Trajectory", y = "False positive rate") +
  scale_x_discrete(labels = c("Standard", "SESOI")) +
  scale_color_manual(breaks = c("T1", "T2"),
                    values = c("#E69F00", "#0072B2")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(strip.text.x = element_text(size = 14, colour = "black")) +
  theme(strip.text.y = element_text(size = 14, colour = "black")) +
  theme(strip.background = element_rect(fill = "white", color = "black")) +
  theme(legend.position = "none")

plot_FPR

facet_names <- c(
  "0.5" = "SESOI = 0.5",
  "1" = "SESOI = 1.0")

plot_FNR <-
  ggplot(data = plot_data, 
         aes(x = factor(trajectory), 
             y = FNR,
             color = trajectory)) +
  geom_point(size = 3, alpha = .8) +
  facet_grid(SESOI ~ distribution, labeller = labeller(.rows = facet_names)) +
  labs(x = "Trajectory", y = "False negative rate") +
  scale_x_discrete(labels = c("Standard", "SESOI")) +
  scale_color_manual(breaks = c("T1", "T2"),
                    values = c("#E69F00", "#0072B2")) +
  theme_bw() +
  theme(axis.title.x = element_text(size = 16)) +
  theme(axis.title.y = element_text(size = 16)) +
  theme(axis.text.x = element_text(size = 15, colour = "black")) +
  theme(axis.text.y = element_text(size = 15, colour = "black")) +
  theme(strip.text.x = element_text(size = 14, colour = "black")) +
  theme(strip.text.y = element_text(size = 14, colour = "black")) +
  theme(strip.background = element_rect(fill = "white", color = "black")) +
  theme(legend.position = "none")

plot_FNR
```


\newpage

**Methods**

\scriptsize

\ \ \ \ **Simulation.**We explored different approaches to perform preclinical animal experiments via simulations. To this end, we modeled a simplified preclinical research trajectory from the exploratory stage to the results of a within-lab replication study (Figure \@ref(fig:trajectory)). Along the trajectory, there are different ways to increase the probability of not missing potentially meaningful effects. After an initial exploratory study, a first decision identifies experiments for replication. In our simulation, we employed two different decision criteria that indicate when one should move from the exploratory to confirmatory mode. If a decision has been made to replicate an initial study, we applied two approaches to determine the sample size for a replication study (smallest effect size of interest (SESOI) and standard power analysis), as outlined in detail below.

\ \ \ \ We explored different approaches to perform preclinical animal experiments via simulations. To this end, we modeled a simplified preclinical research trajectory from the exploratory stage to the results of a within-lab replication study (Figure \@ref(fig:trajectory) \textcolor{red}{make new figure and include two trajectories in MS and all 4 in Supplement}). Along the trajectory, there are different ways to increase the probability of not missing potentially meaningful effects. After an initial exploratory study, a first decision identifies experiments for replication. In our simulation, we employed two different decision criteria that indicate when one should move from the exploratory stage to the replication [if you use this lingo, it should match the one in the intro] stage. If a decision has been made to replicate an initial study, we applied two approaches to determine the sample size for a replication study (smallest effect size of interest (SESOI) and standard power analysis), as outlined in detail below.

```{r, echo = FALSE, results = FALSE}
library(png)
library(knitr)
img1_path <- "trajectory_proposal.png"
img1 <- readPNG(img1_path, native = TRUE, info = TRUE)
attr(img1, "info")
```

```{r trajectory, echo = FALSE, message = FALSE, out.width = "80%", fig.cap = "A preclinical research trajectory from the exploratory stage to a within-lab replication. The four panels along the arrow display four possible combinations of decision criteria and approaches to calculate the sample size for replication that can be employed throughout the trajectory.", fig.align = 'center'}
include_graphics(img1_path)
```

\ \ \ \ *Empirical effect size distributions.*Simulations were based on empirical effect size distributions from the recently published literature  [@szucs2017empirical; @carneiro2018effect]. This enabled us to determine the prior probability (pre-study odds) of a certain alternative hypothesis ($H_{1}$) which we defined as an effect of a given size (e.g. a Cohen's *d* of 0.5). The two distributions reflect different research fields. 

The distribution of effect sizes extracted from Szucs & Ioannidis (2017) [@szucs2017empirical] contains 26841 effect sizes from the cognitive neuroscience and psychology literature published between January 2011 and August 2014. All effect sizes are calculated as the standardized difference in means (Cohen's *d*). Effect size estimates range from `r round(min(ES_data_Szucs$D), 2)` to `r round(max(ES_data_Szucs$D), 2)`, and have a median of `r round(median(ES_data_Szucs$D), 2)`. As the pre-study odds of a medium effect of 0.5 are rather large (`r round(outcomes_all_distributions_init_samp_size_10$prev_pop[6], 2)`), we will refer to this distribution as "optimistic". We acknowledge that the effect sizes were mainly extracted from human studies. However, in large parts the distribution is in agreement with effect sizes reported to be typical of (some areas of) preclinical research (find good ref here \textcolor{red}{[This could be infectious diseases, usually antibiotics are all or nothing effects]}). 

As our study is concerned specifically with preclinical research, we chose a second distribution of empirical effect sizes to represent one field of the preclinical realm. Carneiro et al.'s (2018) [@carneiro2018effect] study systematically examined effect sizes in the rodent fear conditioning literature. Effect sizes were extracted from 410 experiments published in PubMed in 2013. The publication included a data file containing all extracted effect sizes. After removing missing values, the data set consisted of 336 effect sizes, again, calculated as Cohen's *d*. The effect sizes range from `r round(min(ES_data_Carneiro$D), 2)` to `r round(max(ES_data_Carneiro$D), 2)`, and have a median of `r round(median(ES_data_Carneiro$D), 2)`. The prior probability of observing an effect of 0.5 is `r round(outcomes_all_distributions_init_samp_size_10$prev_pop[2], 2)`. We will therefore refer to this distribution as "pessimistic". [in the limitations section you could cite the Bioarxiv paper and compare the two distributions to support your choice and that it may not be overly pessimistic. Particular in fields where there was no progress like neurodegenerative diseases]

\ \ \ \ *Exploratory stage.*From each of the two distributions, we drew 10000 samples of effect sizes from which we created 10000 study data sets. Each data set comprised data of two groups consisting of ten experimental units each drawn from a normal distribution. We chose a number of ten EUs based on reported sample sizes in preclinical studies [@howells2014bringing]. [For the limitation section we need to argue that different initial sample sizes like 7 or 15 will not change results dramatically]. Our simulated design mimics a comparison between two groups where one receives an intervention and the other functions as a control group. The study data sets are compared using a two-sided two-sample *t*-test. From these exploratory study results, we extracted the *p*-values and 95 percent confidence intervals (CI). We then employed two different criteria based on the *p*-value or 95 percent CI, respectively, to decide whether to continue to a replication. 

\ \ \ \ *Decision criteria to proceed to replication.*The first decision criterion employs the conventional significance threshold  ($\alpha$ = .05) to decide whether to replicate an exploratory study. If a *p*-value extracted from a two-sided two-sample *t*-test is $\leq$ .05, this study will proceed to the replication stage. If not, the trajectory is terminated after the exploratory study. We chose this decision criterion as our reference, as this is what we consider to be current practice. 

As an alternative to this approach, we propose to set a smallest effect size of interest (SESOI) and examine whether the 95 percent CI around the exploratory effect size estimate covers this SESOI. A SESOI is the effect size that the researcher based their knowledge of the literature in their respective field (domain knowledge) and given practical constraints considers biologically and clinically meaningful [@lakens2018equivalence]. In our simulation, we used 0.5 and 1.0 as SESOI. This approach emphasizes the importance of effect sizes rather than statistical significance to evaluate an intervention's effect. Further, we expected this approach to be more lenient than statistical significance (at least if the significance threshold was set at $\alpha$ = .05) and to allow a broader range of effect sizes to pass on to be further investigated. 

\ \ \ \ *Approaches to determine sample size for replication.* Once the decision to continue to replication has been made, we employed two different approaches to determine the sample size for the replication study. After having conducted an exploratory study, we have an estimate of the direction of the effect. Only effect sizes that showed an effect that favors the treatment over the control group were considered for further investigation. Thus, for the replication study, a one-sided two-sample *t*-test was performed. The desired power level for replication was set to .80, $\alpha$ was set to .05. In order to calculate the sample size for replication given power and $\alpha$, an effect size estimate is required. In one approach, we used the exploratory effect size estimate to compute the replication sample size. In an alternative approach, we employed the same SESOI used as decision criterion earlier. In statistical terms, our SESOI was set such that the replication study would have a power of .50 to detect an effect of this size (# explain in more detail and find good ref to motivate this: Lakens? \textcolor{red}{[This is mainly to ensure that the likelihood of a type I error below this threshold is negligible. The goal is to reduce Type I error in this second phase.]}). Consequently, in the first approach, the replication sample size was dependent on the outcome of the exploratory study, whereas using a SESOI always yielded the same sample size regardless of the exploratory effect size (e.g. 23 EUs in each group for a SESOI of 0.5).

\ \ \ \ *Replication stage.* For each of the studies that met the decision criterion after the exploratory study (either *p* $\leq$ .05 or SESOI within the 95 percent CI of the exploratory effect size estimate), a replication study was performed. The number of replication studies conducted varied with the decision criterion used and, in case of the criterion employing a SESOI, also with the SESOI (0.5 and 1.0). A replication study was performed as a one-sided two-sample *t*-test, where the number of animals in each group was determined by the approach to calculate the sample size. For a replication be considered "successful", the *p*-value had to be below the conventional significance threshold ($\alpha$ = .05).

\ \ \ \ *Trajectories.* We compared the two trajectories (Standard and SESOI) regarding the number of experiments proceeding to the replication stage, number of animals needed in the replication, and positive predictive value across the trajectory. Secondary outcomes are the false positive rate, false negative rate, and effect size precision. Outcome variables are outlined in more detail in the following section. The standard trajectory constitutes our reference, as we consider it to be closest to current practice. We have stored data, results, and figures of all four trajectories in an online repository (insert URL here).

\newpage

**References**
\ \ \ \ 
\singlespacing
