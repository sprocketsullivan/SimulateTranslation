future_map(list_exploratory_data[[i]], get_summary_study)
}
selection_equiv <- list()
for (i in 1:length(samp_size_vector)) {
selection_equiv[[i]] <- future_map(exploratory_data_summary[[i]], get_decision_equiv,
SESOI = 1.0)
}
row_names <- NULL
col_names <- c("init_sample_size", "study_id", "t_value",
"p_value", "CI_lower", "CI_upper", "effect")
df <- as_tibble(matrix(unlist(exploratory_data_summary),
nrow = n_exp*length(samp_size_vector), byrow = TRUE,
dimnames = list(c(row_names),
c(col_names))))
col_name <- "selection_equiv"
df_equiv <- as_tibble(matrix(unlist(selection_equiv),
nrow = n_exp*length(samp_size_vector), byrow = TRUE,
dimnames = list(c(row_names),
c(col_name))))
dat <- bind_cols(df, df_equiv)
dat$ES_true <- current_ES
hist(dat$ES_true, breaks = 100)
setwd("~/Documents/QUEST/PhD/R/SimulateTranslation")
rm(list = ls())
source("./scripts/simulation/sim_fixN_Carneiro_decision_equivalence_with_SESOI.R")
dat
sum(dat$effect < 0) # empirical effect sizes are negative because t.test function takes control - treat
sum(dat$effect > 0)
sum(dat$ES_true < 0)
data <-
dat %>%
group_by(init_sample_size, study_id) %>%
filter(selection_equiv == 1)
sum(data$effect < 0)
sum(data$effect > 0)
sum(data$effect == 0)
selected <-
data %>%
group_by(init_sample_size) %>%
summarize(selected = sum(selection_equiv == 1))
rep_sample_size_std <- NULL
for (i in 1:nrow(data)) {
rep_sample_size_std[i] <-
ceiling(calc_sample_size(data = data[i, ], sample_size = data[i, ]$init_sample_size,
method = 2, SESOI = 1.0, power = 0.5))
}
data$rep_samp_size_std <- rep_sample_size_std
max(data$rep_samp_size_std)
hist(data$effect)
data$effect <- ifelse(data$effect < 0, -data$effect, -data$effect)
hist(data$effect, breaks = 200)
hist(data$ES_true, breaks = 200)
sum(data$effect > 0)
sum(data$effect < 0)
sum(data$effect == 0)
negative_ES <-
data %>%
group_by(init_sample_size) %>%
summarize(neg_ES = sum(effect < 0))
percent_selected <-
selected %>%
mutate(neg_ES = negative_ES$neg_ES,
selected_no_negatives = selected-neg_ES,
per_selected = selected_no_negatives / 10000 * 100)
rep_attempts <-
rep(c(percent_selected$selected_no_negatives[1],
percent_selected$selected_no_negatives[2],
percent_selected$selected_no_negatives[3]),
c(percent_selected$selected_no_negatives[1],
percent_selected$selected_no_negatives[2],
percent_selected$selected_no_negatives[3]))
replication_data <- list()
rep_exp_no <- 0
select_experiments <- which(data$selection_equiv == 1)
select_experiments <- select_experiments[data$effect[select_experiments] >= 0 ]
current_ES_rep <- data$ES_true
for(i in select_experiments) {
rep_exp_no <- rep_exp_no + 1
replication_data[[rep_exp_no]] <-
generate_study(ES_true = current_ES_rep[i],
sample_size = rep_sample_size_std[i])
replication_data[[rep_exp_no]] <-
replication_data[[rep_exp_no]] %>%
mutate(study_id = rep_exp_no)
}
plan(multiprocess)
rep_data_summary <-
future_map(replication_data, get_summary_study_rep)
res_summary_rep <-
data.frame(init_sample_size = data$init_sample_size[select_experiments],
rep_no = c(1:rep_exp_no),
rep_sample_size = rep_sample_size_std[select_experiments],
#rep_sample_size = rep_sample_size_std,
t_value = unlist(map(rep_data_summary, "t_value")),
p_value = unlist(map(rep_data_summary, "p_value")), #[seq(1, 2*rep_exp_no, 2)],
effect = unlist(map(rep_data_summary, "effect")),
ES_true = data$ES_true[select_experiments],
rep_attempts = rep_attempts)
hist(res_summary_rep$effect, breaks = 200)
res_summary_rep$effect <- ifelse(res_summary_rep$effect < 0,
-res_summary_rep$effect, -res_summary_rep$effect)
write.csv(res_summary_rep,
file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_equiv_method2_1.0")
setwd("~/Documents/QUEST/PhD/R/SimulateTranslation/")
rm(list = ls())
library(tidyverse)
library(compute.es)
final_sig_Szucs <- read.csv(file = "./data/Szucs_distribution/Frequentist_analysis/Szucs_distribution_sig_method1")
final_sig_Szucs$distribution <- "Optimistic"
final_sig_Szucs$trajectory <- "T1"
final_equiv_Szucs <- read.csv(file = "./data/Szucs_distribution/Frequentist_analysis/Szucs_distribution_equiv_method2_0.5")
final_equiv_Szucs$distribution <- "Optimistic"
final_equiv_Szucs$trajectory <- "T2 with SESOI = 0.5"
final_equiv_Szucs_1 <- read.csv(file = "./data/Szucs_distribution/Frequentist_analysis/Szucs_distribution_equiv_method2_1.0")
final_equiv_Szucs_1$distribution <- "Optimistic"
final_equiv_Szucs_1$trajectory <- "T2 with SESOI = 1.0"
final_sig_Carneiro <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_sig_method1")
final_sig_Carneiro$distribution <- "Pessimistic"
final_sig_Carneiro$trajectory <- "T1"
final_equiv_Carneiro <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_equiv_method2_0.5")
final_equiv_Carneiro$distribution <- "Pessimistic"
final_equiv_Carneiro$trajectory <- "T2 with SESOI = 0.5"
final_equiv_Carneiro_1 <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_equiv_method2_1.0")
final_equiv_Carneiro_1$distribution <- "Pessimistic"
final_equiv_Carneiro_1$trajectory <- "T2 with SESOI = 1.0"
final <- bind_rows(final_sig_Szucs,
final_equiv_Szucs,
final_equiv_Szucs_1,
final_sig_Carneiro,
final_equiv_Carneiro,
final_equiv_Carneiro_1)
final_init_samp_size_10 <-
final %>%
filter(init_sample_size == 10)
### add column for outcome significant / not significant to match outcome column
### of sequential design data set
final_init_samp_size_10$H0 <- ifelse(final_init_samp_size_10$p_value <= .05, 2, 1)
final_init_samp_size_10 <-
final_init_samp_size_10 %>%
group_by(distribution, trajectory) %>%
filter(H0 == 2)
# hist(final_init_samp_size_10$ES_true, breaks = 100)
# max(final_init_samp_size_10$ES_true)
# median(final_init_samp_size_10$ES_true)
# mean(final_init_samp_size_10$ES_true)
#
# hist(final_init_samp_size_10$effect, breaks = 100)
# max(final_init_samp_size_10$effect)
# median(final_init_samp_size_10$effect)
# mean(final_init_samp_size_10$effect)
#
# plot(final_init_samp_size_10$effect)
# plot(final_init_samp_size_10$ES_true)
### compute CI around effect size
final_init_samp_size_10$t_value <- ifelse(final_init_samp_size_10$t_value < 0,
- final_init_samp_size_10$t_value,
- final_init_samp_size_10$t_value)
final_init_samp_size_10$CI_lower <- tes(t = final_init_samp_size_10$t_value,
n.1 = final_init_samp_size_10$rep_sample_size,
n.2 = final_init_samp_size_10$rep_sample_size)$l.d
final_init_samp_size_10$CI_upper <- tes(t = final_init_samp_size_10$t_value,
n.1 = final_init_samp_size_10$rep_sample_size,
n.2 = final_init_samp_size_10$rep_sample_size)$u.d
# final_init_samp_size_10$median_ES_true <- median(final_init_samp_size_10$ES_true)
# final_init_samp_size_10$median_effect <- median(final_init_samp_size_10$effect)
plot_data <-
final_init_samp_size_10 %>%
group_by(distribution, trajectory) %>%
summarize(mean_effect = mean(effect),
median_effect = median(effect),
mean_CI_lower = mean(CI_lower),
mean_CI_upper = mean(CI_upper),
median_ES_true = median(ES_true),
mean_ES_true = mean(ES_true))
ggplot(data = plot_data) +
facet_wrap(~ distribution) +
geom_errorbar(aes(x = trajectory,
ymin = mean_effect - mean_CI_lower,
ymax = mean_effect + mean_CI_upper),
width = 0.09,
color = "red",
position = "dodge") +
geom_point(aes(x = trajectory, y = mean_effect),
size = 2.5, color = "red") +
geom_point(aes(x = trajectory, y = median_ES_true),
size = 2.5, color = "blue") +
labs(x = "Trajectory", y = "Mean effect size (with 95% CI)") +
theme_bw() +
theme(axis.title.x = element_text(size = 14)) +
theme(axis.title.y = element_text(size = 14)) +
theme(axis.text.x = element_text(size = 12, colour = "black")) +
theme(axis.text.y = element_text(size = 12, colour = "black")) +
theme(strip.text.x = element_text(size = 15, colour = "black", face = "bold")) +
theme(strip.background = element_rect(fill = "white", color = "black"))
# theme(legend.title = element_text(size = 15, face = "bold")) +
# theme(legend.text = element_text(size = 14))
# sum(final_init_samp_size_10$effect > final_init_samp_size_10$ES_true)
# sum(final_init_samp_size_10$effect < final_init_samp_size_10$ES_true)
final_equiv_Carneiro_1 <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_equiv_method2_1.0")
final_equiv_Carneiro_1$distribution <- "Pessimistic"
final_equiv_Carneiro_1$trajectory <- "T2 \n SESOI = 1.0"
View(final_equiv_Carneiro_1)
rm(list = ls())
library(tidyverse)
library(compute.es)
### read in data sets from the different trajectories
### using fixed-N design in replication study
# final <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_equiv_method2_1.0")
final_sig_Szucs <- read.csv(file = "./data/Szucs_distribution/Frequentist_analysis/Szucs_distribution_sig_method1")
final_sig_Szucs$distribution <- "Optimistic"
final_sig_Szucs$trajectory <- "T1"
final_equiv_Szucs <- read.csv(file = "./data/Szucs_distribution/Frequentist_analysis/Szucs_distribution_equiv_method2_0.5")
final_equiv_Szucs$distribution <- "Optimistic"
final_equiv_Szucs$trajectory <- "T2 SESOI = 0.5"
final_equiv_Szucs_1 <- read.csv(file = "./data/Szucs_distribution/Frequentist_analysis/Szucs_distribution_equiv_method2_1.0")
final_equiv_Szucs_1$distribution <- "Optimistic"
final_equiv_Szucs_1$trajectory <- "T2 SESOI = 1.0"
final_sig_Carneiro <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_sig_method1")
final_sig_Carneiro$distribution <- "Pessimistic"
final_sig_Carneiro$trajectory <- "T1"
final_equiv_Carneiro <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_equiv_method2_0.5")
final_equiv_Carneiro$distribution <- "Pessimistic"
final_equiv_Carneiro$trajectory <- "T2 SESOI = 0.5"
final_equiv_Carneiro_1 <- read.csv(file = "./data/Carneiro_distribution/Frequentist_analysis/Carneiro_distribution_equiv_method2_1.0")
final_equiv_Carneiro_1$distribution <- "Pessimistic"
final_equiv_Carneiro_1$trajectory <- "T2 SESOI = 1.0"
final <- bind_rows(final_sig_Szucs,
final_equiv_Szucs,
final_equiv_Szucs_1,
final_sig_Carneiro,
final_equiv_Carneiro,
final_equiv_Carneiro_1)
final_init_samp_size_10 <-
final %>%
filter(init_sample_size == 10)
### add column for outcome significant / not significant to match outcome column
### of sequential design data set
final_init_samp_size_10$H0 <- ifelse(final_init_samp_size_10$p_value <= .05, 2, 1)
final_init_samp_size_10 <-
final_init_samp_size_10 %>%
group_by(distribution, trajectory) %>%
filter(H0 == 2)
# hist(final_init_samp_size_10$ES_true, breaks = 100)
# max(final_init_samp_size_10$ES_true)
# median(final_init_samp_size_10$ES_true)
# mean(final_init_samp_size_10$ES_true)
#
# hist(final_init_samp_size_10$effect, breaks = 100)
# max(final_init_samp_size_10$effect)
# median(final_init_samp_size_10$effect)
# mean(final_init_samp_size_10$effect)
#
# plot(final_init_samp_size_10$effect)
# plot(final_init_samp_size_10$ES_true)
### compute CI around effect size
final_init_samp_size_10$t_value <- ifelse(final_init_samp_size_10$t_value < 0,
- final_init_samp_size_10$t_value,
- final_init_samp_size_10$t_value)
final_init_samp_size_10$CI_lower <- tes(t = final_init_samp_size_10$t_value,
n.1 = final_init_samp_size_10$rep_sample_size,
n.2 = final_init_samp_size_10$rep_sample_size)$l.d
final_init_samp_size_10$CI_upper <- tes(t = final_init_samp_size_10$t_value,
n.1 = final_init_samp_size_10$rep_sample_size,
n.2 = final_init_samp_size_10$rep_sample_size)$u.d
# final_init_samp_size_10$median_ES_true <- median(final_init_samp_size_10$ES_true)
# final_init_samp_size_10$median_effect <- median(final_init_samp_size_10$effect)
plot_data <-
final_init_samp_size_10 %>%
group_by(distribution, trajectory) %>%
summarize(mean_effect = mean(effect),
median_effect = median(effect),
mean_CI_lower = mean(CI_lower),
mean_CI_upper = mean(CI_upper),
median_ES_true = median(ES_true),
mean_ES_true = mean(ES_true))
ggplot(data = plot_data) +
facet_wrap(~ distribution) +
geom_errorbar(aes(x = trajectory,
ymin = mean_effect - mean_CI_lower,
ymax = mean_effect + mean_CI_upper),
width = 0.09,
color = "red",
position = "dodge") +
geom_point(aes(x = trajectory, y = mean_effect),
size = 2.5, color = "red") +
geom_point(aes(x = trajectory, y = median_ES_true),
size = 2.5, color = "blue") +
labs(x = "Trajectory", y = "Mean effect size (with 95% CI)") +
theme_bw() +
theme(axis.title.x = element_text(size = 14)) +
theme(axis.title.y = element_text(size = 14)) +
theme(axis.text.x = element_text(size = 12, colour = "black")) +
theme(axis.text.y = element_text(size = 12, colour = "black")) +
theme(strip.text.x = element_text(size = 15, colour = "black", face = "bold")) +
theme(strip.background = element_rect(fill = "white", color = "black"))
# theme(legend.title = element_text(size = 15, face = "bold")) +
# theme(legend.text = element_text(size = 14))
# sum(final_init_samp_size_10$effect > final_init_samp_size_10$ES_true)
# sum(final_init_samp_size_10$effect < final_init_samp_size_10$ES_true)
setwd("~/Documents/QUEST/PhD/R/SimulateTranslation")
rm(list = ls())
# source additional functions
source("./scripts/simulation/load_packages.R")
source("./scripts/simulation/load_data_Szucs.R")
source("./scripts/simulation/functions_for_sim_BF.R")
library(foreach)
library(doMC)
registerDoMC(cores = 4)
library(doParallel)
registerDoParallel()
getDoParWorkers()
n_exp <- 3
ES_true <- ES_data_Szucs$D
set.seed(4321)
current_ES <- sample(ES_true, n_exp)
hist(ES_true, breaks = 200)
hist(current_ES, breaks = 200)
current_ES
#how many hypothesis over SESOI threshold
SESOI       <- c(.5, 1)
mat <- matrix(NA, nrow = 3, ncol = length(SESOI),
dimnames = list(c("prev_pop", "all_positives", "all_negatives"),
c(.5, 1)))
prev_pop      <- vector()
all_positives <- vector()
all_negatives <- vector()
counter = 0
for (ES in SESOI) {
counter = counter + 1
prev <- round(sum(ES_true > ES)/length(ES_true), 3)
all_pos <- sum(current_ES > ES)
all_neg <- n_exp - all_pos
print(ES)
prev_pop[counter] <- prev
all_positives[counter] <- all_pos
all_negatives[counter] <- all_neg
}
mat[1, ] <- prev_pop
mat[2, ] <- all_positives
mat[3, ] <- all_negatives
mat
samp_size_vector <- c(7, 10, 15)
list_exploratory_data <-
foreach(samp_size = samp_size_vector) %do% {
exploratory_data <- list()
for(i in 1:n_exp) {
exploratory_data[[i]] <- generate_study(current_ES[i])
exploratory_data[[i]] <-
exploratory_data[[i]] %>%
mutate(study_id = i,
ES_true = current_ES[i])
}
list_exploratory_data <- exploratory_data
}
#the confidence interval generated here is used in the equivalence test
exploratory_data_summary <- list()
plan(multiprocess)
for (i in 1:length(samp_size_vector)) {
exploratory_data_summary[[i]] <-
future_map(list_exploratory_data[[i]], get_summary_study)
}
# decision to go on
# this decision depends on whether exploratory result is significant (p <= .05) or not
# select studies for replication if p-value < .05
selection_sig <- list()
for (i in 1:length(samp_size_vector)) {
selection_sig[[i]] <-
future_map(exploratory_data_summary[[i]], get_decision_sig, pval_threshold = 0.05)
}
row_names <- NULL
col_names <- c("init_sample_size", "study_id", "t_value",
"p_value", "CI_lower", "CI_upper", "effect")
df <- as_tibble(matrix(unlist(exploratory_data_summary),
nrow = n_exp*length(samp_size_vector), byrow = TRUE,
dimnames = list(c(row_names),
c(col_names))))
col_name <- "selection_sig"
df_sig <- as_tibble(matrix(unlist(selection_sig),
nrow = n_exp*length(samp_size_vector), byrow = TRUE,
dimnames = list(c(row_names),
c(col_name))))
dat <- bind_cols(df, df_sig)
View(dat)
dat$ES_true <- current_ES
View(dat)
dat
sum(dat$effect < 0) # empirical effect sizes are negative because t.test function takes control - treat
sum(dat$effect > 0)
sum(dat$ES_true < 0)
data <-
dat %>%
group_by(init_sample_size, study_id) %>%
filter(selection_equiv == 1)
data <-
dat %>%
group_by(init_sample_size, study_id) %>%
filter(selection_sig == 1)
View(data)
sum(data$effect < 0)
sum(data$effect > 0)
sum(data$effect == 0)
selected <-
data %>%
group_by(init_sample_size) %>%
summarize(selected = sum(selection_sig == 1))
rep_sample_size_std <- NULL
for (i in 1:nrow(data)) {
rep_sample_size_std[i] <-
ceiling(calc_sample_size(data = data[i, ], sample_size = data[i, ]$init_sample_size,
method = 2, SESOI = 1.0, power = 0.5))
}
rep_sample_size_std <- NULL
for (i in 1:nrow(data)) {
rep_sample_size_std[i] <-
ceiling(calc_sample_size(data = data[i, ], sample_size = data[i, ]$init_sample_size,
method = 1, SESOI = 1.0, power = 0.5))
}
rep_sample_size_std <- NULL
for (i in 1:nrow(data)) {
rep_sample_size_std[i] <-
ceiling(calc_sample_size(data = data[i, ], sample_size = data[i, ]$init_sample_size,
method = 1))
# rep_sample_size_std[i] <-
#   ceiling(calc_sample_size(data = data[i, ], sample_size = data[i, ]$init_sample_size,
#                            method = 2, SESOI = 0.5, power = .5))
}
rep_sample_size_std <- NULL
for (i in 1:nrow(data)) {
rep_sample_size_std[i] <-
ceiling(calc_sample_size(data = data[i, ], sample_size = data[i, ]$init_sample_size,
method = 1))
# rep_sample_size_std[i] <-
#   ceiling(calc_sample_size(data = data[i, ], sample_size = data[i, ]$init_sample_size,
#                            method = 2, SESOI = 0.5, power = .5))
}
ceiling(power.t.test(n = NULL, delta = .9737	, sd = 1, sig.level = .05, power = .8,
type = "two.sample",
alternative = "one.sided")$n)
ceiling(power.t.test(n = NULL, delta = -.9737	, sd = 1, sig.level = .05, power = .8,
type = "two.sample",
alternative = "one.sided")$n)
ceiling(power.t.test(n = NULL, delta = .9737	, sd = 1, sig.level = .05, power = .8,
type = "two.sample",
alternative = "one.sided")$n)
ceiling(power.t.test(n = NULL, delta = 1.9138	, sd = 1, sig.level = .05, power = .8,
type = "two.sample",
alternative = "one.sided")$n)
ceiling(power.t.test(n = NULL, delta = 1.4771	, sd = 1, sig.level = .05, power = .8,
type = "two.sample",
alternative = "one.sided")$n)
ceiling(power.t.test(n = NULL, delta = 1.4190	, sd = 1, sig.level = .05, power = .8,
type = "two.sample",
alternative = "one.sided")$n)
data$rep_samp_size_std <- rep_sample_size_std
View(data)
max(data$rep_samp_size_std)
hist(data$effect, breaks = 100)
data$effect <- ifelse(data$effect < 0, -data$effect, -data$effect)
hist(data$effect, breaks = 200)
hist(data$ES_true, breaks = 200)
sum(data$effect > 0)
sum(data$effect < 0)
sum(data$effect == 0)
negative_ES <-
data %>%
group_by(init_sample_size) %>%
summarize(neg_ES = sum(effect < 0))
percent_selected <-
selected %>%
mutate(neg_ES = negative_ES$neg_ES,
selected_no_negatives = selected-neg_ES,
per_selected = selected_no_negatives / 10000 * 100)
rep_attempts <-
rep(c(percent_selected$selected_no_negatives[1],
percent_selected$selected_no_negatives[2],
percent_selected$selected_no_negatives[3]),
c(percent_selected$selected_no_negatives[1],
percent_selected$selected_no_negatives[2],
percent_selected$selected_no_negatives[3]))
replication_data <- list()
rep_exp_no <- 0
select_experiments <- which(data$selection_sig == 1)
select_experiments <- select_experiments[data$effect[select_experiments] >= 0 ]
current_ES_rep <- data$ES_true
for(i in select_experiments) {
rep_exp_no <- rep_exp_no + 1
replication_data[[rep_exp_no]] <-
generate_study(ES_true = current_ES_rep[i],
sample_size = rep_sample_size_std[i])
replication_data[[rep_exp_no]] <-
replication_data[[rep_exp_no]] %>%
mutate(study_id = rep_exp_no)
}
plan(multiprocess)
rep_data_summary <-
future_map(replication_data, get_summary_study_rep)
View(rep_data_summary)
res_summary_rep <-
data.frame(init_sample_size = data$init_sample_size[select_experiments],
rep_no = c(1:rep_exp_no),
rep_sample_size = rep_sample_size_std[select_experiments],
#rep_sample_size = rep_sample_size_std,
t_value = unlist(map(rep_data_summary, "t_value")),
p_value = unlist(map(rep_data_summary, "p_value")), #[seq(1, 2*rep_exp_no, 2)],
effect = unlist(map(rep_data_summary, "effect")),
ES_true = data$ES_true[select_experiments],
rep_attempts = rep_attempts)
hist(res_summary_rep$effect, breaks = 200)
res_summary_rep$effect <- ifelse(res_summary_rep$effect < 0,
-res_summary_rep$effect, -res_summary_rep$effect)
View(res_summary_rep)
View(selected)
